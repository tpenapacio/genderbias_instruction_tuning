{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rv3aDCYKsHqD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import spatial\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "import re\n",
        "from scipy.spatial import distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nNa4cTXsLz8",
        "outputId": "05f7dee6-93a9-486b-9c6d-16f84a2cb8e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# if mounting on google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yw9tlF2Use1A"
      },
      "outputs": [],
      "source": [
        "# download glove embeddings with spec 840b 300d\n",
        "embeddings_dict = {}\n",
        "error = []\n",
        "with open(\"glove.840B/glove.840B.300d.txt\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        try:\n",
        "          vector = np.asarray(values[1:], \"float32\")\n",
        "          embeddings_dict[word] = vector\n",
        "        except:\n",
        "          error.append(word)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/adimaini/WEAT-WEFAT/blob/main/src/lib/weat.py\n",
        "import numpy as np\n",
        "import itertools\n",
        "from scipy import stats\n",
        "from scipy.stats.stats import zscore\n",
        "import statistics\n",
        "\n",
        "class Weat:\n",
        "\n",
        "    def cos_similarity(self, tar, att):\n",
        "        '''\n",
        "        Calculates the cosine similarity of the target variable vs the attribute\n",
        "        '''\n",
        "        score = np.dot(tar, att) / (np.linalg.norm(tar) * np.linalg.norm(att))\n",
        "        return score\n",
        "\n",
        "\n",
        "    def mean_cos_similarity(self, tar, att):\n",
        "        '''\n",
        "        Calculates the mean of the cosine similarity between the target and the range of attributes\n",
        "        '''\n",
        "        mean_cos = np.mean([self.cos_similarity(tar, attribute) for attribute in att])\n",
        "        return mean_cos\n",
        "\n",
        "\n",
        "    def association(self, tar, att1, att2):\n",
        "        '''\n",
        "        Calculates the mean association between a single target and all of the attributes\n",
        "        '''\n",
        "        association = self.mean_cos_similarity(tar, att1) - self.mean_cos_similarity(tar, att2)\n",
        "        return association\n",
        "\n",
        "    def differential_association(self, t1, t2, att1, att2):\n",
        "        '''\n",
        "        xyz\n",
        "        '''\n",
        "        diff_association = np.sum([self.association(tar1, att1, att2) for tar1 in t1]) - \\\n",
        "                        np.sum([self.association(tar2, att1, att2) for tar2 in t2])\n",
        "        return diff_association\n",
        "\n",
        "\n",
        "    def effect_size(self, t1, t2, att1, att2):\n",
        "        '''\n",
        "        Calculates the effect size (d) between the two target variables and the attributes\n",
        "        Parameters:\n",
        "            t1 (np.array): first target variable matrix\n",
        "            t2 (np.array): second target variable matrix\n",
        "            att1 (np.array): first attribute variable matrix\n",
        "            att2 (np.array): second attribute variable matrix\n",
        "\n",
        "        Returns:\n",
        "            effect_size (float): The effect size, d.\n",
        "\n",
        "        Example:\n",
        "            t1 (np.array): Matrix of word embeddings for professions \"Programmer, Scientist, Engineer\"\n",
        "            t2 (np.array): Matrix of word embeddings for professions \"Nurse, Librarian, Teacher\"\n",
        "            att1 (np.array): matrix of word embeddings for males (man, husband, male, etc)\n",
        "            att2 (np.array): matrix of word embeddings for females (woman, wife, female, etc)\n",
        "        '''\n",
        "        combined = np.concatenate([t1, t2])\n",
        "        num1 = np.mean([self.association(target, att1, att2) for target in t1])\n",
        "        num2 = np.mean([self.association(target, att1, att2) for target in t2])\n",
        "        combined_association = np.array([self.association(target, att1, att2) for target in combined])\n",
        "        dof = combined_association.shape[0]\n",
        "        denom = np.sqrt(((dof-1)*np.std(combined_association, ddof=1) ** 2 ) / (dof-1))\n",
        "        effect_size = (num1 - num2) / denom\n",
        "        return effect_size\n",
        "\n",
        "\n",
        "\n",
        "    def p_value(self, t1, t2, att1, att2):\n",
        "        '''\n",
        "        calculates the p value associated with the weat test\n",
        "        '''\n",
        "        diff_association = self.differential_association(t1, t2, att1, att2)\n",
        "        target_words = np.concatenate([t1, t2])\n",
        "        np.random.shuffle(target_words)\n",
        "\n",
        "        # check if join of t1 and t2 have even number of elements, if not, remove last element\n",
        "        if target_words.shape[0] % 2 != 0:\n",
        "            target_words = target_words[:-1]\n",
        "\n",
        "        partition_differentiation = []\n",
        "        for i in range(10000):\n",
        "            seq = np.random.permutation(target_words)\n",
        "            tar1_words = seq[:len(target_words) // 2]\n",
        "            tar2_words = seq[len(target_words) // 2:]\n",
        "            partition_differentiation.append(\n",
        "                self.differential_association(tar1_words, tar2_words, att1, att2)\n",
        "                )\n",
        "\n",
        "        mean = np.mean(partition_differentiation)\n",
        "        stdev = np.std(partition_differentiation)\n",
        "        p_val = 1 - stats.norm(loc=mean, scale=stdev).cdf(diff_association)\n",
        "\n",
        "        # print(\"Mean: \", mean, \"\\n\\n\", \"stdev: \", stdev, \"\\n\\n partition ass: \", partition_differentiation, '\\n\\n association: ', diff_association, '\\n\\n p value: ', p_val)\n",
        "        return p_val, diff_association, partition_differentiation\n",
        "\n",
        "class Wefat(Weat):\n",
        "\n",
        "    def effect_size(self, tar, att1, att2):\n",
        "        '''\n",
        "        Calculates the effect size (d) between the target variable vector and the attributes\n",
        "\n",
        "        Parameters:\n",
        "            tar (np.array):  target variable vector\n",
        "            att1 (np.array): first attribute variable matrix\n",
        "            att2 (np.array): second attribute variable matrix\n",
        "\n",
        "        Returns:\n",
        "            effect_size (float): The effect size, d.\n",
        "\n",
        "        Example:\n",
        "            tar (np.array): Vector of word embeddings for a profession \"Programmer\"\n",
        "            att1 (np.array): matrix of word embeddings for males (man, husband, male, etc)\n",
        "            att2 (np.array): matrix of word embeddings for females (woman, wife, female, etc)\n",
        "        '''\n",
        "        if len(tar)==300: # check to ensure that it is a vector, and not a matrix\n",
        "            combined = np.concatenate([att1, att2])\n",
        "            num = self.association(tar, att1, att2)\n",
        "            cos_similarities = np.array([self.cos_similarity(tar, att) for att in combined])\n",
        "            dof = cos_similarities.shape[0]\n",
        "            denom = np.sqrt(((dof-1)*np.std(cos_similarities, ddof=1) **2 ) / (dof-1))\n",
        "            effect_size = num / denom\n",
        "            return effect_size\n",
        "        else:\n",
        "            raise ValueError(\"Passed array is not a vector, but a matrix\")\n",
        "\n",
        "    def p_value(self, tar, att1, att2):\n",
        "        '''\n",
        "        calculates the p-value associated with the wefat test\n",
        "        '''\n",
        "        association = self.association(tar, att1, att2)\n",
        "        attributes = np.concatenate([att1, att2])\n",
        "        np.random.shuffle(attributes)\n",
        "\n",
        "        # check if join of t1 and t2 have even number of elements, if not, remove last element\n",
        "        if attributes.shape[0] % 2 != 0:\n",
        "            attributes = attributes[:-1]\n",
        "\n",
        "        partition_association = []\n",
        "        for i in range(1000000):\n",
        "            seq = np.random.permutation(attributes)\n",
        "            att1_words = seq[:len(attributes) // 2]\n",
        "            att2_words = seq[len(attributes) // 2:]\n",
        "            partition_association.append(\n",
        "                self.association(tar, att1_words, att2_words)\n",
        "                )\n",
        "\n",
        "        mean = np.mean(partition_association)\n",
        "        stdev = np.std(partition_association)\n",
        "        p_val = 1 - stats.norm(loc=mean, scale=stdev).cdf(association)\n",
        "        # print(\"Mean: \", mean, \"\\n\\n\", \"stdev: \", stdev, \"\\n\\n partition ass: \", partition_association, '\\n\\n association: ', association, '\\n\\n p value: ', p_val)\n",
        "        return p_val, association, partition_association"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F5wwbuINZy_",
        "outputId": "e9f8cb51-0d3b-45c8-fcfd-49239cfb57b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-bce3d4c2f507>:5: DeprecationWarning: Please use `zscore` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
            "  from scipy.stats.stats import zscore\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bobldqBsgmI"
      },
      "outputs": [],
      "source": [
        "# family of gender attributes\n",
        "female_attributes = [\"female\", \"woman\", \"girl\", \"sister\", \"she\", \"her\", \"hers\", \"daughter\"]\n",
        "male_attributes = [\"male\", \"man\", \"boy\", \"brother\", \"he\", \"him\", \"his\", \"son\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3uirG3ZvMml"
      },
      "outputs": [],
      "source": [
        "# embeddings\n",
        "female_embed = np.array([embeddings_dict[i] for i in female_attributes])\n",
        "male_embed = np.array([embeddings_dict[i] for i in male_attributes])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "female = pd.read_csv(\"female_model_generations.csv\")\n",
        "male = pd.read_csv(\"male_model_generations.csv\")\n",
        "neutral = pd.read_csv(\"neutral_model_generations.csv\")\n",
        "prompts = pd.concat([female, male, neutral])"
      ],
      "metadata": {
        "id": "zI8m91uwJavx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vvql7YeZx2dY"
      },
      "outputs": [],
      "source": [
        "female_to_male = {\"woman\":\"man\", \"father\": \"mother\", \"girl\": \"boy\", \"mother\": \"father\", \"boy\":\"girl\", \"man\":\"woman\", \"she\": \"he\", \"husband\":\"wife\", \"daughter\": \"son\", \"uncle\":\"aunt\", \"brother\":\"sister\", \"nephew\":\"niece\",\n",
        "\"female\":\"male\", \"grandmother\":'grandfather', \"grandson\": \"granddaughter\", \"girlfriend\": \"boyfriends\", \"fatherinlaw\":\"sisterinlaw\", \"lady\":\"gentleman\", \"him\":\"her\"}\n",
        "male_to_female = {v:k for k,v in female_to_male.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jf-y21oj8b9n"
      },
      "outputs": [],
      "source": [
        "# isolate career and gender attributes from instances\n",
        "# the following two code blocks assumes you are working with DYNAMIC PROMPT 2\n",
        "prompts = female\n",
        "\n",
        "regex = re.compile('[^a-zA-Z]')\n",
        "prompts_list = list(prompts['Task'])\n",
        "stimuli = []\n",
        "for i in prompts_list:\n",
        "  pattern = r\"[‘’'](\\w+)[‘’']\"\n",
        "  s = re.findall(pattern, i)\n",
        "  if len(s) == 3:\n",
        "    stimuli.append(s)\n",
        "  else:\n",
        "    try:\n",
        "      if s[0] in female_to_male:\n",
        "        s.append(female_to_male[s[0]])\n",
        "        stimuli.append(s)\n",
        "      elif s[0] in male_to_female:\n",
        "        s.append(male_to_female[s[0]])\n",
        "        stimuli.append(s)\n",
        "    except:\n",
        "      continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeP9-p3k8nFh"
      },
      "outputs": [],
      "source": [
        "new_df = pd.DataFrame()\n",
        "weat = Wefat()\n",
        "for i in range(len(stimuli)):\n",
        "  if (stimuli[i][0] not in embeddings_dict):\n",
        "    print(stimuli[i][0])\n",
        "  elif (stimuli[i][1] not in embeddings_dict):\n",
        "    print(stimuli[i][1])\n",
        "  else:\n",
        "    target_embedding = embeddings_dict[stimuli[i][1]]\n",
        "    row = dict(prompts.iloc[i])\n",
        "    effect_size = weat.effect_size(target_embedding, female_embed, male_embed)\n",
        "\n",
        "    row['effect_size'] = effect_size\n",
        "    new_df = pd.concat([new_df, pd.DataFrame(row, index=[i])], ignore_index=True)\n",
        "new_df.to_csv(\"neutral_gen_weat_scores.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}