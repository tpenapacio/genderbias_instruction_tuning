{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3YZ4ZZQ2xBJ",
        "outputId": "a494b279-c7e5-48e7-ae8a-f526e93218fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# if mounting on google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyQT6CrbjyzT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from openai import OpenAI\n",
        "OPEN_API_KEY = \"\"\n",
        "client = OpenAI(api_key=OPEN_API_KEY)\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_85U4g-qa7e"
      },
      "outputs": [],
      "source": [
        "# insert names of fine-tuned models or outof the box models here\n",
        "female_model = \"ft:gpt-3.5-turbo-0125:personal::9KAqA7S4\"\n",
        "male_model = \"ft:gpt-3.5-turbo-0125:personal::9KApTlQn\"\n",
        "neutral_model = \"ft:gpt-3.5-turbo-0125:personal::9KApJkIv\"\n",
        "box = \"gpt-3.5-turbo\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cxbh5ths3CWm"
      },
      "outputs": [],
      "source": [
        "filenames = [\"promt2_template.txt\"]\n",
        "out_filename = \"\"\n",
        "for filename in filenames:\n",
        "  print(filename)\n",
        "  f = open(filename ,mode='r', encoding='utf-8-sig')\n",
        "  prompt = f.read()\n",
        "  f.close()\n",
        "\n",
        "  input = {\"role\": \"user\", \"content\": prompt}\n",
        "  generated = []\n",
        "  generations = pd.DataFrame(columns = ['Task', 'Output'])\n",
        "  num = 0\n",
        "\n",
        "  # generate at least 200 instnces\n",
        "  while num < 200:\n",
        "    completion = client.chat.completions.create(\n",
        "      model=neutral_model,\n",
        "      messages=[\n",
        "        input\n",
        "      ]\n",
        "    )\n",
        "\n",
        "    tasks = []\n",
        "    outputs = []\n",
        "    message = completion.choices[0].message.content.strip().split(\"\\n\\n\")\n",
        "    for i in message:\n",
        "\n",
        "      # this checks that the output matches our expected format\n",
        "      try:\n",
        "        task, output = i.split(\"\\n\")\n",
        "        task = task.replace(\"Task: \", \"\")\n",
        "        output = output.replace(\"Output: \", \"\")\n",
        "        new_df = pd.DataFrame([{\"Task\": task, \"Output\": output}])\n",
        "        generations = pd.concat([generations, new_df], ignore_index=True)\n",
        "        num = num + 1\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "    # modify input\n",
        "    for i in message:\n",
        "      if i not in generated:\n",
        "        generated.append(message)\n",
        "\n",
        "    prompt_split = prompt.split(\"\\n\\n\")\n",
        "    print(num)\n",
        "\n",
        "    # replace 2 prompts\n",
        "    \"\"\"\n",
        "    for i in range(2):\n",
        "      rand_prompt = random.randint(1,9)\n",
        "      rand_gen = random.randint(0, len(message) - 1)\n",
        "      prompt_split = prompt.split(\"\\n\\n\")\n",
        "      prompt_split[rand_prompt] = message[rand_gen]\n",
        "    prompt = \"\\n\\n\".join(prompt_split)\n",
        "    input = input = {\"role\": \"user\", \"content\": prompt}\n",
        "    name = filename.split(\".\")[0]\n",
        "    \"\"\"\n",
        "  generations.to_csv(out_filename)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}